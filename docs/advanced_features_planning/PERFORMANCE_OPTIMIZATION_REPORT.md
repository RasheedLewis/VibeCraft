# Performance Optimization Report

**Date:** 2025-11-23  
**Scope:** Deep dive analysis of performance bottlenecks and optimization opportunities

---

## ğŸ¯ Implementation Decisions

**Selected for Implementation:**
- âœ… **#1** - Parallel clip downloads in composition pipeline
- âœ… **#2** - Fix N+1 query pattern in `get_clips_for_composition`
- âœ… **#3** - Reduce session creation in loops
- âœ… **#5** - Add database index on `SongClip.status`
- âœ… **#8** - Fix sequential normalization in legacy code path â­ **HIGHEST PRIORITY**

**Not Implementing:**
- All other items (#4, #6, #7, #9-20) - deferred for now

---

## Executive Summary

This report identifies **8 critical performance issues** and **12 optimization opportunities** across database queries, file I/O, network operations, and code structure. Estimated impact: **30-60% reduction in response times** for key operations.

---

## ğŸ”´ Critical Issues (High Priority)

### 1. Sequential Clip Downloads in Composition Pipeline

**Location:** `backend/app/services/composition_execution.py:124-144`

**High-Level Flow:** Composition pipeline flow:
1. **Validate inputs** - Check song, get clips from DB
2. **Download clips and audio** - Download from S3/URLs to temp directory â† **BOTTLENECK HERE**
3. **Normalize clips** - Convert to consistent format (already parallelized)
4. **Beat-align clips** - Adjust timing to match beats
5. **Apply visual effects** - Beat-synced effects (flash, color burst, etc.)
6. **Concatenate** - Stitch clips together with audio
7. **Upload to S3** - Store final composed video
8. **Create DB record** - Save metadata

**Issue:** Clips are downloaded sequentially in a loop, creating a bottleneck:
```python
for i, (clip_url, clip) in enumerate(zip(clip_urls, clips)):
    response = httpx.get(clip_url, timeout=60.0, follow_redirects=True)
    clip_path.write_bytes(response.content)
```

**Impact:** 
- For 4 clips at 10MB each: ~40 seconds sequential vs ~10 seconds parallel
- Blocks composition pipeline unnecessarily
- This is Step 2 of the pipeline, so it delays all subsequent steps

**Solution:** Use `ThreadPoolExecutor` or `asyncio` to download clips in parallel (similar to normalization which is already parallelized in Step 3).

**Estimated Improvement:** 3-4x faster clip downloads

---

### 2. N+1 Query Pattern in `get_clips_for_composition`

**Location:** `backend/app/services/clip_model_selector.py:82-115`

**High-Level Purpose:** Clip validation ensures:
- Clip exists in database
- Clip belongs to the correct song (security check)
- Clip status is "completed" (ready for composition)
- Clip has a `video_url` (has been generated)

**Issue:** Loops through clip_ids and calls `get_and_validate_clip` for each:
```python
for clip_id in clip_ids:
    clip = get_and_validate_clip(session, clip_id, song.id, use_sections)
```

Each call creates a separate database query (`session.get(model_class, clip_id)`). For 4 clips, this results in 4 queries instead of 1.

**Impact:**
- 4x database round trips
- Slower response times under load
- Each query also validates ownership and status, which could be done in memory after bulk fetch

**Solution:** Use `session.query(SongClip).filter(SongClip.id.in_(clip_ids)).all()` to fetch all clips in a single query, then validate in memory (check `song_id`, `status`, `video_url`).

**Estimated Improvement:** 2-3x faster for multi-clip operations

---

### 3. Excessive Session Creation in Loops

**Location:** `backend/app/services/composition_execution.py:124-130`

**Issue:** Creates a new database session for each iteration to check cancellation:
```python
for i, (clip_url, clip) in enumerate(zip(clip_urls, clips)):
    with session_scope() as session:  # New session each iteration!
        job = session.get(CompositionJob, job_id)
```

**Impact:**
- Unnecessary connection overhead
- Database connection pool exhaustion under load

**Solution:** Check cancellation once before the loop, or use a single session with periodic checks (every N iterations).

**Estimated Improvement:** 10-20% reduction in database overhead

---

### 4. Sequential S3 Object Existence Checks

**Location:** `backend/app/services/clip_generation.py:760-766`

**Issue:** Loops through possible S3 keys and checks each sequentially:
```python
for key in possible_keys:
    if check_s3_object_exists(bucket_name=bucket, key=key):
        found_key = key
        break
```

**Impact:**
- Up to 4 sequential S3 API calls (each ~100-200ms)
- Blocks composition startup

**Solution:** Use `concurrent.futures` to check all keys in parallel, return first match.

**Estimated Improvement:** 3-4x faster key discovery

---

### 5. Missing Database Index on `SongClip.status`

**Location:** `backend/app/models/clip.py:27`

**Issue:** `status` field is used in WHERE clauses but has no index:
```python
status: str = Field(default="queued", max_length=32)  # No index!
```

**Query:** `ClipRepository.get_completed_by_song_id()` filters by status:
```python
.where(SongClip.status == "completed")
```

**Impact:**
- Full table scans for status queries
- Degrades with large clip counts

**Solution:** Add `index=True` to status field, or create composite index `(song_id, status)`.

**Estimated Improvement:** 10-100x faster status queries (depending on table size)

---

### 6. Sequential Presigned URL Generation

**Location:** `backend/app/services/clip_generation.py:347-464`

**Issue:** In `get_clip_generation_summary`, presigned URLs are generated sequentially:
```python
if song.composed_video_s3_key and bucket:
    composed_video_url = generate_presigned_get_url(...)
if song.composed_video_poster_s3_key and bucket:
    composed_video_poster_url = generate_presigned_get_url(...)
```

**Impact:**
- Each presigned URL generation is a synchronous S3 API call (~50-100ms)
- Blocks summary generation

**Solution:** Generate both URLs in parallel using `ThreadPoolExecutor` or `asyncio`.

**Estimated Improvement:** 2x faster URL generation

---

### 7. No Eager Loading for Related Data

**Location:** `backend/app/services/clip_generation.py:347-349`

**High-Level Purpose:** `get_clip_generation_summary` is the main status endpoint used by the frontend to:
- Show progress (completed/failed/processing/queued counts)
- Display list of all clips with their status
- Get composed video URL (if available)
- Get analysis data (BPM, beats, sections, etc.)
- Called frequently during polling (every few seconds while clips are generating)

**Issue:** `get_clip_generation_summary` loads song and clips separately, then later loads analysis:
```python
song = SongRepository.get_by_id(song_id)  # Query 1
clips = ClipRepository.get_by_song_id(song_id)  # Query 2
# ... later ...
analysis = get_latest_analysis(song_id)  # Query 3
```

**Impact:**
- 3 separate database round trips
- Called frequently during polling, so this multiplies the overhead
- Could be optimized with a single query using JOINs

**Solution:** Use SQLModel relationships or manual JOINs to fetch song + clips + analysis in one query (if analysis is frequently needed). Alternatively, cache analysis data since it rarely changes.

**Estimated Improvement:** 2-3x faster summary generation

---

### 8. Sequential Clip Normalization in Legacy Code

**Location:** `backend/app/services/clip_generation.py:727-907` (legacy `compose_song_video`)

**Two Composition Code Paths:**

1. **Legacy Path (`compose_song_video`):**
   - Used by: `/songs/{id}/clips/compose` (sync) and `/songs/{id}/clips/compose/async` (async job)
   - For: `SongClip` model (short-form videos)
   - Currently used by: **Frontend** âœ…
   - Normalizes clips **sequentially** in a loop

2. **New Path (`execute_composition_pipeline`):**
   - Used by: `/songs/{id}/compose` (async job)
   - For: `SectionVideo` model (full-length videos with sections)
   - Currently used by: **Not used by frontend** (future feature)
   - Normalizes clips **in parallel** using ThreadPoolExecutor

**Issue:** Legacy path (`compose_song_video`) normalizes clips sequentially:
```python
for idx, clip in enumerate(completed_clips):
    normalize_clip(str(source_path), str(normalized_path))
```

**Impact:**
- Legacy path is 3-4x slower than new path for normalization
- Since frontend uses legacy path, users experience slower composition
- Code duplication - both paths do similar work

**Solution:** 
- Option A: Update `compose_song_video` to use parallel normalization (copy from new path)
- Option B: Migrate frontend to use new path (requires refactoring)
- Option C: Consolidate both paths into one unified pipeline

**Estimated Improvement:** 3-4x faster normalization (if legacy path is updated)

---

## ğŸŸ¡ Medium Priority Optimizations

### 9. Missing Index on `Song.created_at`

**Location:** `backend/app/models/song.py:45`

**Issue:** `created_at` is used in ORDER BY but may not have an index:
```python
created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
```

**Query:** `list_songs()` orders by `created_at DESC`:
```python
.order_by(Song.created_at.desc())
.limit(5)  # Limited to 5 songs per user
```

**Impact:**
- Users are limited to 5 songs, so table size per user is small
- **However:** With many users, total table size grows, and ORDER BY without index can still be slow
- PostgreSQL may use index for ORDER BY even with LIMIT

**Solution:** Add `index=True` to `created_at` field. Low cost, good practice, helps with multi-user scenarios.

**Estimated Improvement:** 5-10x faster song listing queries (more impactful as user base grows)

---

### 10. S3 Object Existence Check Before Presigned URL

**Location:** `backend/app/services/clip_generation.py:414-416`

**Issue:** Checks if S3 object exists before generating presigned URL:
```python
if check_s3_object_exists(bucket_name=bucket, key=song.composed_video_s3_key):
    composed_video_url = generate_presigned_get_url(...)
```

**Impact:**
- Extra S3 API call (~100-200ms)
- Presigned URLs work even if object doesn't exist (client gets 404)

**Solution:** Remove existence check, generate presigned URL directly. Let client handle 404.

**Estimated Improvement:** 100-200ms faster per URL generation

---

### 11. Multiple Database Sessions in `get_clip_generation_job_status`

**Location:** `backend/app/services/clip_generation.py:1157-1178`

**Issue:** Opens multiple sessions:
```python
with session_scope() as session:
    job_record = session.get(ClipGenerationJob, job_id)
# ... later ...
with session_scope() as session:
    job_record = session.get(ClipGenerationJob, job_id)
```

**Impact:**
- Unnecessary connection overhead
- Could use a single session

**Solution:** Combine into a single session scope.

**Estimated Improvement:** 10-20% reduction in overhead

---

### 12. No Caching for Analysis Data

**Location:** `backend/app/services/clip_generation.py:445-448`

**Issue:** `get_clip_generation_summary` calls `get_latest_analysis()` every time:
```python
analysis = get_latest_analysis(song_id)
```

**Impact:**
- Analysis data rarely changes but is fetched on every summary request
- Could be cached for 5-10 minutes

**Solution:** Add Redis/memory cache for analysis data with TTL.

**Estimated Improvement:** 50-90% faster for cached requests

---

## ğŸŸ¢ Low Priority / Future Optimizations

### 13. Async/Await Migration

**Current State:** Most I/O operations are synchronous (S3, HTTP, database).

**Opportunity:** Migrate to async/await for better concurrency:
- FastAPI supports async endpoints
- `httpx.AsyncClient` for async HTTP
- `aioboto3` for async S3 operations
- `asyncpg` for async PostgreSQL

**Impact:** Better resource utilization, higher throughput

**Effort:** High (requires significant refactoring)

---

### 14. Database Connection Pooling Tuning

**Location:** `backend/app/core/database.py:25`

**Issue:** Default connection pool settings may not be optimal:
```python
engine = create_engine(database_url, echo=False, connect_args=connect_args)
```

**Opportunity:** Configure pool size, max overflow, pool timeout based on load:
```python
engine = create_engine(
    database_url,
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_pre_ping=True,
)
```

**Impact:** Better handling of concurrent requests

---

### 15. Batch Database Updates

**Location:** Various services

**Issue:** Individual `session.add()` and `session.commit()` calls for multiple records.

**Opportunity:** Use `session.bulk_update_mappings()` or `session.bulk_insert_mappings()` for batch operations.

**Impact:** Faster bulk operations

---

### 16. Query Result Pagination

**Location:** `backend/app/repositories/song_repository.py:36-45`

**Issue:** `get_all()` loads all songs without pagination:
```python
def get_all() -> list[Song]:
    statement = select(Song).order_by(Song.created_at.desc())
    return list(session.exec(statement).all())
```

**Opportunity:** Add pagination support (limit/offset or cursor-based).

**Impact:** Lower memory usage, faster queries for large datasets

---

### 17. Lazy Loading vs Eager Loading Strategy

**Current State:** Using explicit repository methods (good), but could optimize JOINs.

**Opportunity:** Use SQLModel relationships with `selectinload()` or `joinedload()` for frequently accessed related data.

**Impact:** Fewer queries for related data access

---

### 18. S3 Multipart Upload for Large Files

**Location:** `backend/app/services/storage.py:71-86`

**Issue:** `upload_bytes_to_s3` uploads entire file in one request.

**Opportunity:** Use S3 multipart upload for files > 5MB.

**Impact:** Faster uploads, better reliability for large files

---

### 19. HTTP Client Connection Pooling

**Location:** `backend/app/services/composition_execution.py:135`

**Issue:** Creates new HTTP connection for each download:
```python
response = httpx.get(clip_url, timeout=60.0, follow_redirects=True)
```

**Opportunity:** Use a shared `httpx.Client` with connection pooling:
```python
client = httpx.Client(timeout=60.0, follow_redirects=True)
response = client.get(clip_url)
```

**Impact:** Faster HTTP requests, lower connection overhead

---

### 20. Database Query Logging in Development

**Current State:** `echo=False` in database engine.

**Opportunity:** Add query logging middleware or use SQLAlchemy query logging to identify slow queries in development.

**Impact:** Better visibility into query performance

---

## ğŸ“Š Performance Impact Summary

| Optimization | Priority | Estimated Improvement | Effort |
|-------------|----------|----------------------|--------|
| Parallel clip downloads | ğŸ”´ Critical | 3-4x faster | Medium |
| Fix N+1 in get_clips_for_composition | ğŸ”´ Critical | 2-3x faster | Low |
| Reduce session creation in loops | ğŸ”´ Critical | 10-20% faster | Low |
| Parallel S3 existence checks | ğŸ”´ Critical | 3-4x faster | Low |
| Add index on SongClip.status | ğŸ”´ Critical | 10-100x faster | Very Low |
| Parallel presigned URL generation | ğŸ”´ Critical | 2x faster | Low |
| Eager loading for summaries | ğŸ”´ Critical | 2-3x faster | Medium |
| Fix legacy sequential normalization | ğŸ”´ Critical | 3-4x faster | Low |
| Add index on Song.created_at | ğŸŸ¡ Medium | 5-10x faster | Very Low |
| Remove unnecessary S3 checks | ğŸŸ¡ Medium | 100-200ms faster | Very Low |
| Cache analysis data | ğŸŸ¡ Medium | 50-90% faster (cached) | Medium |
| Async/await migration | ğŸŸ¢ Low | Better concurrency | High |

**Total Estimated Improvement:** 30-60% reduction in response times for critical paths

---

## ğŸ¯ Recommended Implementation Order

### Phase 1: Quick Wins (1-2 days)
1. Add index on `SongClip.status` (5 minutes)
2. Add index on `Song.created_at` (5 minutes)
3. Remove unnecessary S3 existence checks (30 minutes)
4. Reduce session creation in loops (1 hour)
5. Parallel presigned URL generation (1 hour)

### Phase 2: High Impact (2-3 days)
6. Fix N+1 in `get_clips_for_composition` (2 hours)
7. Parallel clip downloads (3-4 hours)
8. Parallel S3 existence checks (1 hour)
9. Single session in `get_clip_generation_job_status` (30 minutes)

### Phase 3: Medium Impact (3-5 days)
10. Eager loading for summaries (4-6 hours)
11. Analysis data caching (4-6 hours)
12. HTTP client connection pooling (2 hours)
13. Deprecate legacy sequential normalization (1 hour)

### Phase 4: Future (1-2 weeks)
14. Async/await migration (major refactor)
15. Database connection pool tuning
16. Batch database updates
17. Query pagination

---

## ğŸ” Monitoring & Validation

### Metrics to Track
- Database query count per request
- Database query duration
- S3 API call count and duration
- HTTP request duration
- Total response time for key endpoints:
  - `GET /songs/{id}/clips/status` (get_clip_generation_summary)
  - `POST /songs/{id}/compose` (composition pipeline)
  - `GET /songs/` (list_songs)

### Tools
- SQLAlchemy query logging
- Application Performance Monitoring (APM)
- Database query analysis (EXPLAIN ANALYZE)
- S3 CloudWatch metrics

---

## ğŸ“ Notes

- **Current State:** Codebase already has some optimizations (parallel normalization in new composition pipeline)
- **Legacy Code:** Old `compose_song_video` function should be deprecated in favor of `execute_composition_pipeline`
- **Testing:** All optimizations should be tested with realistic data volumes (10+ clips, large files)
- **Backward Compatibility:** Ensure optimizations don't break existing functionality

---

## âœ… Verification Checklist

After implementing optimizations, verify:
- [ ] Database query count reduced (use query logging)
- [ ] Response times improved (benchmark before/after)
- [ ] No regressions in functionality (E2E tests)
- [ ] Database indexes are being used (EXPLAIN ANALYZE)
- [ ] Parallel operations actually run in parallel (check logs)
- [ ] Memory usage is acceptable (no leaks from parallel operations)
- [ ] Error handling works correctly (test failure scenarios)

